{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection and Tracking Project\n",
    "\n",
    "The main steps of this project are to:\n",
    "\n",
    "1. Train a classifer to differentiate between cars and non-cars\n",
    "2. Use the classifer to detect and track cars in a video\n",
    "\n",
    "Each step will be done as follows:\n",
    "\n",
    "#### Train a classifer\n",
    "\n",
    "1. Select features to extract from the training set\n",
    "2. Normalize the features\n",
    "3. Train a classifier\n",
    "4. Test the classifer\n",
    "\n",
    "Once a classifer has been sufficiently trained and the overall accuracy is acceptable, it can be used without retraining.\n",
    "\n",
    "#### Vehicle detection\n",
    "\n",
    "1. Use a sliding windows of various sizes to search for positive matches\n",
    "2. Convert the detected matches into a heatmap to combine multiple detections \n",
    "3. Threshold the heatmap to remove false positives\n",
    "4. Draw a bounding box over the original frame of the video using the heatmap to determine location and size\n",
    "\n",
    "---\n",
    "\n",
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Train a classifier\n",
    "\n",
    "### 0. Read in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    \"\"\"Read in the data to train and validate the classifier\n",
    "    \n",
    "    Returns:\n",
    "        A tuple of lists for images of vehicles and images of non-vehicles\"\"\"\n",
    "    \n",
    "    # Used for testing purposes while flushing out the pipeline\n",
    "    VEHICLES_SMALL = 'data/vehicles_smallset/*/*.jpeg'\n",
    "    NON_VEHICLES_SMALL = 'data/non-vehicles_smallset/*/*.jpeg'\n",
    "\n",
    "    # Used for training the final model in some form or another\n",
    "    VEHICLES_FULL = 'data/vehicles/*/*.png'\n",
    "    NON_VEHICLES_FULL = 'data/non-vehicles/*/*.png'\n",
    "    \n",
    "    vehicles = glob.glob(VEHICLES_SMALL)\n",
    "    non_vehicles = glob.glob(NON_VEHICLES_SMALL)\n",
    "\n",
    "    return (vehicles, non_vehicles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cars, notcars = read_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_color(img, to_color_space='RGB', from_color_space='BGR'):\n",
    "\n",
    "    \"\"\"Helper function to convert an image from one color space to another.\n",
    "    The assumption is that the image was read in using OpenCV, hence the\n",
    "    'BGR' color space default.\n",
    "    \n",
    "    Parameters:\n",
    "        • img - input image to convert\n",
    "        • to_color_space - desired color space (default: 'RGB')\n",
    "        • from_color_space - input color space (default: 'BGR')\n",
    "        \n",
    "    Returns:\n",
    "        An image in the new color space or the original image if there was an error\"\"\"\n",
    "    \n",
    "    if to_color_space == from_color_space:\n",
    "        converted_img = np.copy(img)\n",
    "    else:\n",
    "        try:\n",
    "            # get the conversion identifier to use\n",
    "            conversion = getattr(cv2, 'COLOR_{}2{}'.format(from_color_space, to_color_space))\n",
    "        except AttributeError:\n",
    "            return img\n",
    "\n",
    "        # convert image to new color space (if specified)\n",
    "        converted_img = cv2.cvtColor(img, conversion)\n",
    "\n",
    "    return converted_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(32, 32)):\n",
    "\n",
    "    \"\"\"Extract the spatial binned color features\n",
    "    \n",
    "    Parameters:\n",
    "        • img - input image\n",
    "        • size - reduced size of image to use as features\n",
    "        \n",
    "    Returns:\n",
    "        A list of color features based on the resized image\"\"\"\n",
    "\n",
    "    # use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel()\n",
    "\n",
    "    # Return the feature vector\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "\n",
    "    \"\"\"Calculate a histogram for each color channel in the image and create a list of features from them.\n",
    "    \n",
    "    Parameters:\n",
    "        • img - input image\n",
    "        • nbins - number of bins in the histogram\n",
    "        • bins_range - lower and upper range of the bins (above and below are ignored)\n",
    "        \n",
    "    Returns:\n",
    "        A list of color histogram features for the image\"\"\"\n",
    "    \n",
    "    # Compute the histogram of the color channels separately\n",
    "    if len(img.shape) > 2:\n",
    "        hist_features = np.concatenate([np.histogram(img[:, :, c], bins=nbins, range=bins_range)[0] for c in range(img.shape[-1])])\n",
    "    else:\n",
    "        hist_features = np.array([np.histogram(img, bins=nbins, range=bins_range)[0]])\n",
    "        \n",
    "    # return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    \n",
    "    \"\"\"Extract the Histogram of Oriented Gradient (HOG) features for the image.\n",
    "    \n",
    "    Parameters:\n",
    "        • img - input image\n",
    "        • orient - number of orientations for HOG features\n",
    "        • pix_per_cell - cell size over which each gradient histogram is computed\n",
    "        • cell_per_block - specifies the local area over which the histogram counts in a given cell will be normalized\n",
    "        • vis - boolean to enable a visualization of the HOG\n",
    "        • feature_vec - boolean to return the data as a feature vector\n",
    "        \n",
    "    Returns:\n",
    "        The HOG features will be returned either multidimensional or as a feature vector depending on `feature_vec`.\n",
    "        If `vis` is true, an image representation of the HOG is also returned.\"\"\"\n",
    "    \n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True,\n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:\n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True,\n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9,\n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    \n",
    "    \"\"\"Extract features from the input images based on the parameters passed in.\n",
    "    \n",
    "    Parameters:\n",
    "        • imgs - a list of input images\n",
    "        • color_space - desired color space to extract features\n",
    "        • spatial_size - size for spacial binning of color features\n",
    "        • hist_bins - number of bins for the color histogram features\n",
    "        • orient - number of orientations for HOG features\n",
    "        • pix_per_cell - cell size over which each gradient histogram is computed\n",
    "        • cell_per_block - specifies the local area over which the histogram counts in a given cell will be normalized\n",
    "        • hog_channel - image channel to apply the Histogram of Oriented Gradient (HOG)\n",
    "        • spatial_feat - boolean to enable spatial binning of color features\n",
    "        • hist_feat - boolean to enable color histogram features\n",
    "        • hog_feat - boolean to enable HOG features\n",
    "        \n",
    "    Returns:\n",
    "        A list of features per image\"\"\"\n",
    "    \n",
    "    # create a list to append feature vectors to\n",
    "    features = []\n",
    "    \n",
    "    # iterate through the list of images\n",
    "    for file in imgs:\n",
    "\n",
    "        # features for this single file\n",
    "        file_features = []\n",
    "\n",
    "        # read in each one by one\n",
    "        img = cv2.imread(file)\n",
    "\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        feature_img = convert_color(img, color_space)\n",
    "        \n",
    "        # extract spatial binning of color features, if enabled\n",
    "        if spatial_feat:\n",
    "            spatial_features = bin_spatial(feature_img, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "            \n",
    "        # extract color histogram features, if enabled\n",
    "        if hist_feat:\n",
    "            hist_features = color_hist(feature_img, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "            \n",
    "        if hog_feat:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_img[:,:,channel],\n",
    "                                        orient, pix_per_cell, cell_per_block,\n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)\n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_img[:,:,hog_channel], orient,\n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_features = extract_features(cars)\n",
    "notcar_features = extract_features(cars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
