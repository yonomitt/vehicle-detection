{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vehicle Detection and Tracking Project\n",
    "\n",
    "The main steps of this project are to:\n",
    "\n",
    "1. Train a classifer to differentiate between cars and non-cars\n",
    "2. Use the classifer to detect and track cars in a video\n",
    "\n",
    "Each step will be done as follows:\n",
    "\n",
    "#### Train a classifer\n",
    "\n",
    "1. Select features to extract from the training set\n",
    "2. Prepare the data\n",
    "3. Train a classifier\n",
    "4. Test the classifer\n",
    "\n",
    "Once a classifer has been sufficiently trained and the overall accuracy is acceptable, it can be used without retraining.\n",
    "\n",
    "#### Vehicle detection\n",
    "\n",
    "1. Use a sliding windows of various sizes to search for positive matches\n",
    "2. Convert the detected matches into a heatmap to combine multiple detections \n",
    "3. Threshold the heatmap to remove false positives\n",
    "4. Draw a bounding box over the original frame of the video using the heatmap to determine location and size\n",
    "\n",
    "---\n",
    "\n",
    "### Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "\n",
    "try:\n",
    "    # scikit-learn version >= 0.18\n",
    "    from sklearn.model_selection import train_test_split\n",
    "except:\n",
    "    # scikit-learn version <= 0.17\n",
    "    from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# visualizations will be shown in the notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "## Train a classifier\n",
    "\n",
    "### 0. Read in the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \n",
    "    \"\"\"Read in the data to train and validate the classifier\n",
    "    \n",
    "    Returns:\n",
    "        A tuple of lists for images of vehicles and images of non-vehicles\"\"\"\n",
    "    \n",
    "    # Used for testing purposes while flushing out the pipeline\n",
    "    VEHICLES_SMALL = 'data/vehicles_smallset/*/*.jpeg'\n",
    "    NON_VEHICLES_SMALL = 'data/non-vehicles_smallset/*/*.jpeg'\n",
    "\n",
    "    # Used for training the final model in some form or another\n",
    "    VEHICLES_FULL = 'data/vehicles/*/*.png'\n",
    "    NON_VEHICLES_FULL = 'data/non-vehicles/*/*.png'\n",
    "    \n",
    "    vehicles = glob.glob(VEHICLES_SMALL)\n",
    "    non_vehicles = glob.glob(NON_VEHICLES_SMALL)\n",
    "\n",
    "    return (vehicles, non_vehicles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cars, notcars = read_data()\n",
    "\n",
    "print('cars: {}, notcars: {}'.format(len(cars), len(notcars)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_collage(filenames):\n",
    "    \n",
    "    \"\"\"Create a collage of the images\n",
    "    \n",
    "    Parameters:\n",
    "        • filenames - a list of image filenames\n",
    "        \n",
    "    Returns:\n",
    "        A collage image\"\"\"\n",
    "    \n",
    "    cols = math.ceil(math.sqrt(len(filenames)))\n",
    "    rows = math.ceil(len(filenames) / cols)\n",
    "\n",
    "    w, h, d = (64, 64, 3)\n",
    "\n",
    "    collage = np.zeros((cols * w, rows * h, d), dtype='uint8')\n",
    "\n",
    "    col = row = 0\n",
    "\n",
    "    for i, filename in enumerate(filenames):\n",
    "        img = cv2.imread(filename)        \n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "        x_pos = col * w\n",
    "        y_pos = row * h\n",
    "        collage[x_pos:x_pos + w, y_pos:y_pos + h, :] = img\n",
    "    \n",
    "        col += 1\n",
    "        if col >= cols:\n",
    "            col = 0\n",
    "            row += 1\n",
    "            \n",
    "    return collage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for data_set, title in zip((cars, notcars), ('Cars', 'Non-cars')):\n",
    "    collage = create_collage(random.sample(data_set, min(len(data_set), 9)))\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    plt.imshow(collage);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Feature selection\n",
    "\n",
    "Select the features, on which to train the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_color(img, to_color_space='RGB', from_color_space='BGR'):\n",
    "\n",
    "    \"\"\"Helper function to convert an image from one color space to another.\n",
    "    The assumption is that the image was read in using OpenCV, hence the\n",
    "    'BGR' color space default.\n",
    "    \n",
    "    Parameters:\n",
    "        • img - input image to convert\n",
    "        • to_color_space - desired color space (default: 'RGB')\n",
    "        • from_color_space - input color space (default: 'BGR')\n",
    "        \n",
    "    Returns:\n",
    "        An image in the new color space or the original image if there was an error\"\"\"\n",
    "    \n",
    "    if to_color_space == from_color_space:\n",
    "        converted_img = np.copy(img)\n",
    "    else:\n",
    "        try:\n",
    "            # get the conversion identifier to use\n",
    "            conversion = getattr(cv2, 'COLOR_{}2{}'.format(from_color_space, to_color_space))\n",
    "        except AttributeError:\n",
    "            return img\n",
    "\n",
    "        # convert image to new color space (if specified)\n",
    "        converted_img = cv2.cvtColor(img, conversion)\n",
    "\n",
    "    return converted_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def bin_spatial(img, size=(32, 32)):\n",
    "\n",
    "    \"\"\"Extract the spatial binned color features\n",
    "    \n",
    "    Parameters:\n",
    "        • img - input image\n",
    "        • size - reduced size of image to use as features\n",
    "        \n",
    "    Returns:\n",
    "        A list of color features based on the resized image\"\"\"\n",
    "\n",
    "    # use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel()\n",
    "\n",
    "    # Return the feature vector\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "\n",
    "    \"\"\"Calculate a histogram for each color channel in the image and create a list of features from them.\n",
    "    \n",
    "    Parameters:\n",
    "        • img - input image\n",
    "        • nbins - number of bins in the histogram\n",
    "        • bins_range - lower and upper range of the bins (above and below are ignored)\n",
    "        \n",
    "    Returns:\n",
    "        A list of color histogram features for the image\"\"\"\n",
    "    \n",
    "    # Compute the histogram of the color channels separately\n",
    "    if len(img.shape) > 2:\n",
    "        hist_features = np.concatenate([np.histogram(img[:, :, c], bins=nbins, range=bins_range)[0] for c in range(img.shape[-1])])\n",
    "    else:\n",
    "        hist_features = np.array([np.histogram(img, bins=nbins, range=bins_range)[0]])\n",
    "        \n",
    "    # return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    \n",
    "    \"\"\"Extract the Histogram of Oriented Gradient (HOG) features for the image.\n",
    "    \n",
    "    Parameters:\n",
    "        • img - input image\n",
    "        • orient - number of orientations for HOG features\n",
    "        • pix_per_cell - cell size over which each gradient histogram is computed\n",
    "        • cell_per_block - specifies the local area over which the histogram counts in a given cell will be normalized\n",
    "        • vis - boolean to enable a visualization of the HOG\n",
    "        • feature_vec - boolean to return the data as a feature vector\n",
    "        \n",
    "    Returns:\n",
    "        The HOG features will be returned either multidimensional or as a feature vector depending on `feature_vec`.\n",
    "        If `vis` is true, an image representation of the HOG is also returned.\"\"\"\n",
    "    \n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True,\n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:\n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=True,\n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9,\n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    \n",
    "    \"\"\"Extract features from the input images based on the parameters passed in.\n",
    "    \n",
    "    Parameters:\n",
    "        • imgs - a list of input images\n",
    "        • color_space - desired color space to extract features\n",
    "        • spatial_size - size for spacial binning of color features\n",
    "        • hist_bins - number of bins for the color histogram features\n",
    "        • orient - number of orientations for HOG features\n",
    "        • pix_per_cell - cell size over which each gradient histogram is computed\n",
    "        • cell_per_block - specifies the local area over which the histogram counts in a given cell will be normalized\n",
    "        • hog_channel - image channel to apply the Histogram of Oriented Gradient (HOG)\n",
    "        • spatial_feat - boolean to enable spatial binning of color features\n",
    "        • hist_feat - boolean to enable color histogram features\n",
    "        • hog_feat - boolean to enable HOG features\n",
    "        \n",
    "    Returns:\n",
    "        A list of features per image\"\"\"\n",
    "    \n",
    "    # create a list to append feature vectors to\n",
    "    features = []\n",
    "    \n",
    "    # iterate through the list of images\n",
    "    for file in imgs:\n",
    "\n",
    "        # features for this single file\n",
    "        file_features = []\n",
    "\n",
    "        # read in each one by one\n",
    "        img = cv2.imread(file)\n",
    "\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        feature_img = convert_color(img, color_space)\n",
    "        \n",
    "        # extract spatial binning of color features, if enabled\n",
    "        if spatial_feat:\n",
    "            spatial_features = bin_spatial(feature_img, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "            \n",
    "        # extract color histogram features, if enabled\n",
    "        if hist_feat:\n",
    "            hist_features = color_hist(feature_img, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "            \n",
    "        if hog_feat:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_img.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_img[:,:,channel],\n",
    "                                        orient, pix_per_cell, cell_per_block,\n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)\n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_img[:,:,hog_channel], orient,\n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "color_space = 'LUV' # can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient = 9  # HOG orientations\n",
    "pix_per_cell = 8 # HOG pixels per cell\n",
    "cell_per_block = 2 # HOG cells per block\n",
    "hog_channel = \"ALL\" # can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size = (16, 16) # spatial binning dimensions\n",
    "hist_bins = 16    # number of histogram bins\n",
    "spatial_feat = True # spatial features on or off\n",
    "hist_feat = True # histogram features on or off\n",
    "hog_feat = True # HOG features on or off\n",
    "\n",
    "car_features = extract_features(cars, color_space=color_space,\n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                        orient=orient, pix_per_cell=pix_per_cell,\n",
    "                        cell_per_block=cell_per_block,\n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "notcar_features = extract_features(notcars, color_space=color_space,\n",
    "                        spatial_size=spatial_size, hist_bins=hist_bins,\n",
    "                        orient=orient, pix_per_cell=pix_per_cell,\n",
    "                        cell_per_block=cell_per_block,\n",
    "                        hog_channel=hog_channel, spatial_feat=spatial_feat,\n",
    "                        hist_feat=hist_feat, hog_feat=hog_feat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Prepare the data\n",
    "\n",
    "Prepare the data for training the classifier. Data needs to be normalized, shuffled and split into training and testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prepare_data(true_features, false_features):\n",
    "    \n",
    "    \"\"\"Helper function to prepare the data. This function will normalize the inputs and create the appropriate labels.\n",
    "    \n",
    "    Parameters:\n",
    "        • true_features - features associated with a positive response\n",
    "        • false_features - features associated with a negative response\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of input features (X), associated labels (y), and the scaler used\"\"\"\n",
    "    \n",
    "    # create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "    \n",
    "    # fit a per-column scaler\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    \n",
    "    # apply the scaler to X\n",
    "    scaled_X = scaler.transform(X)\n",
    "    \n",
    "    # define the labels vector\n",
    "    y = np.hstack((np.ones(len(true_features)), np.zeros(len(false_features))))\n",
    "    \n",
    "    return scaled_X, y, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(X, y, test_size=0.2, random_state=None):\n",
    "    \n",
    "    \"\"\"Helper function to split data into training and testing data\n",
    "    \n",
    "    Parameters:\n",
    "        • X - input features matrix\n",
    "        • y - associated labels\n",
    "        • test_size - percentage of the data to be used for testing [0.0, 1.0]\n",
    "        • random_state - number to determine the random state of the algorithm. Useful for consistent testing.\n",
    "        \n",
    "    Returns:\n",
    "        A tuple of X training, X testing, y training, y testing split appropriately.\"\"\"\n",
    "    \n",
    "    # select the random state to initialize\n",
    "    random_state = random_state is None and np.random.randint(0, 100) or random_state\n",
    "\n",
    "    # split up data into randomized training and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n",
    "    \n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create the input feature matrix and the labels for the data\n",
    "X, y, scaler = prepare_data(car_features, notcar_features)\n",
    "\n",
    "# split the data into training and testing\n",
    "X_train, X_test, y_train, y_test = split_data(X, y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Train a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_classifier(X, y, classifier='LinearSVM'):\n",
    "    \n",
    "    \"\"\"Create and train a classifier.\n",
    "    \n",
    "    Parameters:\n",
    "        • X - input feature matrix\n",
    "        • y - labels\n",
    "        • classifer - string indicating desired classifer type\n",
    "        \n",
    "    Returns:\n",
    "        A trained classifier\"\"\"\n",
    "    \n",
    "    # select the classifier\n",
    "    if classifier == 'LinearSVM':\n",
    "        c = LinearSVC()\n",
    "    else:\n",
    "        print(\"WARNING: {} is not currently supported, defaulting to 'LinearSVM'\")\n",
    "        c = LinearSVC()\n",
    "      \n",
    "    # train the classifier\n",
    "    c.fit(X, y)\n",
    "    \n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create a linear SVM\n",
    "svm = train_classifier(X_train, y_train, classifier='LinearSVM')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Test the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_classifier(c, X, y):\n",
    "    \n",
    "    \"\"\"Test the classifier on the inputs provided\n",
    "    \n",
    "    Parameter:\n",
    "        • c - trained classifier\n",
    "        • X - input feature matrix\n",
    "        • y - labels\n",
    "        \n",
    "    Returns:\n",
    "        A float representing the accuracy of the model on this test data.\"\"\"\n",
    "    \n",
    "    return c.score(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test the classifier\n",
    "accuracy = test_classifier(svm, X_test, y_test)\n",
    "\n",
    "print('Classifier accuracy: {:.2f}%'.format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Save the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_classifier(c, name='classifier'):\n",
    "    \n",
    "    \"\"\"Helper function to save the classifer\n",
    "    \n",
    "    Parameters:\n",
    "        • c - classifer\n",
    "        • name - name of the classifier to be used in the file name\"\"\"\n",
    "    \n",
    "    with open('model/{}.p'.format(name), 'wb') as f:\n",
    "        pickle.dump(c, f)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_classifier(svm, 'LinearSVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "---\n",
    "\n",
    "## Vehicle detection\n",
    "\n",
    "### 0. Load the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_classifier(name='classifier'):\n",
    "    \n",
    "    \"\"\"Helper function to load a classifier\n",
    "    \n",
    "    Parameters:\n",
    "        • name - name of the classifer file without the extension or path\n",
    "        \n",
    "    Returns:\n",
    "        A classifer loaded from the file model/`name`.p\"\"\"\n",
    "    \n",
    "    with open('model/{}.p'.format(name), 'rb') as f:\n",
    "        c = pickle.load(f)\n",
    "        \n",
    "    return c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load the classifier\n",
    "svm = load_classifier('LinearSVM')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
